{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import Model \n",
    "from keras.layers import Input, Dense \n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "BASE_FOLDER = Path('../data')\n",
    "sessions = {0: 22, 1: 153, 2: 153}\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value (can actually be different for each attribution step)\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "my_init = glorot_uniform(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(session, split):\n",
    "    return 'zju_gaitaccel_session_' + str(session) + '_' + str(split) + '.csv'\n",
    "\n",
    "def load_session_data(session, split):\n",
    "    filename = get_csv(session, split)\n",
    "    df = pd.read_csv(BASE_FOLDER.joinpath(Path(filename)), header=None)\n",
    "    y = df[df.columns[59]].values\n",
    "    df.drop([df.columns[59]], axis=1, inplace=True)\n",
    "    return df.values, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "SESSION = 1\n",
    "SPLIT = 128\n",
    "INPUT_SIZE = 59\n",
    "\n",
    "X, y = load_session_data(SESSION, SPLIT)\n",
    "num_classes = sessions[SESSION]\n",
    "X = np_utils.normalize(X)\n",
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_frame = Input(shape=(INPUT_SIZE, ))\n",
    "encoded = Dense(32, activation='relu')(input_frame)\n",
    "encoded = Dense(16, activation='relu')(encoded)\n",
    "encoded = Dense(8, activation='relu', name=\"encoded\")(encoded)\n",
    "decoded = Dense(16, activation='relu')(encoded)\n",
    "decoded = Dense(32, activation='relu')(decoded)\n",
    "decoded = Dense(INPUT_SIZE, activation='sigmoid')(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separator loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/53235029/issue-of-batch-sizes-when-using-custom-loss-functions-in-keras\n",
    "def generate_batches(X, batch_size):\n",
    "    currIdx = 0\n",
    "    try:\n",
    "        Xrows, Xcols = X.shape\n",
    "    except ValueError:\n",
    "        Xrows = X.shape[0]\n",
    "        Xcols = 1\n",
    "    batch_x = np.zeros((batch_size, Xcols))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            batch_x[i] = X[currIdx]\n",
    "            currIdx += 1\n",
    "            if currIdx >= Xrows:\n",
    "                currIdx = 0\n",
    "        yield batch_x, batch_x\n",
    "\n",
    "# https://stackoverflow.com/questions/45961428/make-a-custom-loss-function-in-keras\n",
    "def sep_loss(inter_layer):\n",
    "    def sep(X_true, X_pred):\n",
    "        # Get the lower dimensional representation of the data\n",
    "        X_kdim = inter_layer.output\n",
    "        \n",
    "        # Get batch labels        \n",
    "        y = K.flatten(labels)\n",
    "        unique_y, _ = tf.unique(y)\n",
    "        \n",
    "        def diffs_per_label(label):\n",
    "            all_class = tf.boolean_mask(X_kdim, K.flatten((y == label)))\n",
    "            print(all_class)\n",
    "            return K.foldl(lambda diff, x: \n",
    "                           diff + K.reshape(K.sum(K.batch_dot(all_class - x, all_class - x, axes=1), axis=0), ()), \n",
    "                           all_class, \n",
    "                           initializer=0.0)\n",
    "        \n",
    "        intra = K.foldl(lambda acc, label: acc + diffs_per_label(label), unique_y, initializer=0.0)\n",
    "        \n",
    "        mse = K.mean(K.square(X_true - X_pred))\n",
    "        return intra + mse\n",
    "    return sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_TRAIN_SAMPLES = X_train.shape[0]\n",
    "NUM_TEST_SAMPLES = X_test.shape[0]\n",
    "\n",
    "autoencoder = Model(input_frame, decoded)\n",
    "print(autoencoder.summary())\n",
    "# display(SVG(model_to_dot(autoencoder).create(prog='dot', format='svg')))\n",
    "inter_layer = autoencoder.get_layer('encoded')\n",
    "# display(SVG(model_to_dot(x_model).create(prog='dot', format='svg')))\n",
    "\n",
    "labels = K.variable(np.empty((BATCH_SIZE, 1)), dtype='int32', name='labels')\n",
    "train_labels = generate_batches(y_train, BATCH_SIZE)\n",
    "test_labels = generate_batches(y_test, BATCH_SIZE)\n",
    "def changeLabels(epoch, logs):\n",
    "    y_input = K.in_train_phase(train_labels, test_labels)\n",
    "    y, _ = next(y_input)\n",
    "    K.set_value(labels, y)\n",
    "\n",
    "labelChanger = LambdaCallback(on_epoch_start=changeLabels)\n",
    "autoencoder.compile(optimizer='sgd',\n",
    "                    loss=sep_loss(inter_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = autoencoder.fit_generator(generate_batches(X_train, BATCH_SIZE),\n",
    "                epochs=10,\n",
    "                steps_per_epoch=math.ceil(NUM_TRAIN_SAMPLES / BATCH_SIZE),\n",
    "                callbacks = [labelChanger],\n",
    "                validation_data=generate_batches(X_test, BATCH_SIZE),\n",
    "                validation_steps=math.ceil(NUM_TEST_SAMPLES / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
