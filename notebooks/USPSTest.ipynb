{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE:\n",
    "# https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "# https://github.com/skorch-dev/skorch/issues/451\n",
    "# https://tomaugspurger.github.io <- check\n",
    "# https://ml.dask.org/hyper-parameter-search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize': 'x-large',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "pylab.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7291, 256), (7291,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with h5py.File('../data/usps.h5', 'r') as hf:\n",
    "    train = hf.get('train')\n",
    "    X_train = train.get('data')[:]\n",
    "    y_train = train.get('target')[:]\n",
    "    test = hf.get('test')\n",
    "    X_test = test.get('data')[:]\n",
    "    y_test = test.get('target')[:]\n",
    "    \n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7291, 257)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[X_train, y_train].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1194\n",
      "1    1005\n",
      "2     731\n",
      "6     664\n",
      "3     658\n",
      "4     652\n",
      "7     645\n",
      "9     644\n",
      "5     556\n",
      "8     542\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.DataFrame(data=y_train)\n",
    "print(label_df[0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.bincount(y_train)\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(10), counts, width=0.8, align='center', color='#86bf91')\n",
    "ax.set(xticks=range(10), xlim=[-1, 10])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.00000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "      <td>7291.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.024424</td>\n",
       "      <td>0.056131</td>\n",
       "      <td>0.113266</td>\n",
       "      <td>0.194849</td>\n",
       "      <td>0.315504</td>\n",
       "      <td>0.477115</td>\n",
       "      <td>0.47368</td>\n",
       "      <td>0.357718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400727</td>\n",
       "      <td>0.569911</td>\n",
       "      <td>0.558219</td>\n",
       "      <td>0.342946</td>\n",
       "      <td>0.173145</td>\n",
       "      <td>0.081071</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>0.021304</td>\n",
       "      <td>0.010355</td>\n",
       "      <td>0.002661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.025856</td>\n",
       "      <td>0.075601</td>\n",
       "      <td>0.122132</td>\n",
       "      <td>0.180258</td>\n",
       "      <td>0.251330</td>\n",
       "      <td>0.314355</td>\n",
       "      <td>0.358016</td>\n",
       "      <td>0.384152</td>\n",
       "      <td>0.37649</td>\n",
       "      <td>0.373419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386447</td>\n",
       "      <td>0.376492</td>\n",
       "      <td>0.378668</td>\n",
       "      <td>0.362929</td>\n",
       "      <td>0.291277</td>\n",
       "      <td>0.207323</td>\n",
       "      <td>0.150415</td>\n",
       "      <td>0.114350</td>\n",
       "      <td>0.079499</td>\n",
       "      <td>0.033028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.02500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169250</td>\n",
       "      <td>0.131000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.140500</td>\n",
       "      <td>0.530500</td>\n",
       "      <td>0.50100</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323500</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>0.210500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.627250</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>0.83725</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777000</td>\n",
       "      <td>0.917500</td>\n",
       "      <td>0.907500</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>0.247750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.819000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.796000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0            1            2            3            4    \\\n",
       "count  7291.000000  7291.000000  7291.000000  7291.000000  7291.000000   \n",
       "mean      0.001791     0.009431     0.024424     0.056131     0.113266   \n",
       "std       0.025856     0.075601     0.122132     0.180258     0.251330   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.019000   \n",
       "max       0.819000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               5            6            7           8            9    ...  \\\n",
       "count  7291.000000  7291.000000  7291.000000  7291.00000  7291.000000  ...   \n",
       "mean      0.194849     0.315504     0.477115     0.47368     0.357718  ...   \n",
       "std       0.314355     0.358016     0.384152     0.37649     0.373419  ...   \n",
       "min       0.000000     0.000000     0.000000     0.00000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000500     0.02500     0.000000  ...   \n",
       "50%       0.000000     0.140500     0.530500     0.50100     0.219500  ...   \n",
       "75%       0.304500     0.627250     0.848000     0.83725     0.719000  ...   \n",
       "max       1.000000     1.000000     1.000000     1.00000     1.000000  ...   \n",
       "\n",
       "               246          247          248          249          250  \\\n",
       "count  7291.000000  7291.000000  7291.000000  7291.000000  7291.000000   \n",
       "mean      0.400727     0.569911     0.558219     0.342946     0.173145   \n",
       "std       0.386447     0.376492     0.378668     0.362929     0.291277   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.169250     0.131000     0.000000     0.000000   \n",
       "50%       0.323500     0.684000     0.668000     0.210500     0.000000   \n",
       "75%       0.777000     0.917500     0.907500     0.673000     0.247750   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               251          252          253          254          255  \n",
       "count  7291.000000  7291.000000  7291.000000  7291.000000  7291.000000  \n",
       "mean      0.081071     0.038903     0.021304     0.010355     0.002661  \n",
       "std       0.207323     0.150415     0.114350     0.079499     0.033028  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     0.796000  \n",
       "\n",
       "[8 rows x 256 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(data=X_train)\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "INPUT_SIZE = 256\n",
    "ENCODE_DIM = (64, 16)\n",
    "\n",
    "FEAT_EPOCHS = 1000\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class USPSTrainDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        with h5py.File(filename, 'r') as hf:\n",
    "            train = hf.get('train')\n",
    "            self.X = train.get('data')[:]\n",
    "            self.y = train.get('target')[:]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        vector = self.X[index, :]\n",
    "        label = self.y[index]\n",
    "        \n",
    "        return vector, label\n",
    "            \n",
    "class USPSTestDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        with h5py.File(filename, 'r') as hf:\n",
    "            test = hf.get('test')\n",
    "            self.X = test.get('data')[:]\n",
    "            self.y = test.get('target')[:]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        vector = self.X[index, :]\n",
    "        label = self.y[index]\n",
    "        \n",
    "        return vector, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction - Vanilla Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = USPSTrainDataset('../data/usps.h5')\n",
    "test_dataset = USPSTestDataset('../data/usps.h5')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, encode_dim):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, encode_dim[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(encode_dim[0], encode_dim[1]),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.decoder = nn.Sequential(             \n",
    "            nn.Linear(encode_dim[1], encode_dim[0]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(encode_dim[0], input_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_enc = self.encoder(x)\n",
    "        x_dec = self.decoder(x_enc)\n",
    "        return x_dec, x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for data in train_loader:\n",
    "        vec, labels = data\n",
    "        vec = Variable(vec, requires_grad=True).cpu()\n",
    "        \n",
    "        # ===================forward=====================\n",
    "        dec, enc = model(vec)\n",
    "        loss = distance(dec, vec)\n",
    "        \n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('epoch [{}/{}], loss: {:.4f}'.format(epoch + 1, FEAT_EPOCHS, loss.item()))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "model = Autoencoder().cpu()\n",
    "distance = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1, momentum = 0.9)\n",
    "\n",
    "for epoch in range(FEAT_EPOCHS):\n",
    "    loss = train(epoch)\n",
    "    writer.add_scalar('usps/mse', loss, epoch)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './USPS_Feat_1000_lr_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder(INPUT_SIZE, ENCODE_DIM)\n",
    "model.load_state_dict(torch.load('./USPS_Feat_1000_lr_01'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_latent(dataset_loader):\n",
    "    model.eval()\n",
    "    encs = torch.Tensor([])\n",
    "    labels = []\n",
    "    for data in dataset_loader:\n",
    "        vec, label = data\n",
    "        vec = Variable(vec, requires_grad=False).cpu()\n",
    "        _, enc = model(vec)\n",
    "        \n",
    "        encs = torch.cat((encs, enc))\n",
    "        labels.extend([l.tolist() for l in label])\n",
    "        \n",
    "    return encs.detach().numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encs, labels = to_latent(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df = pd.DataFrame(data=np.c_[encs, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_df.to_csv('../data/usps_latent.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "latent_scores = cross_val_score(clf, encs, labels, cv=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent_scores.mean(), latent_scores.std())\n",
    "latent_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "raw_scores = cross_val_score(clf, X_train, y_train, cv=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(raw_scores.mean(), raw_scores.std())\n",
    "raw_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encs, test_labels = to_latent(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "clf.fit(encs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(test_encs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from skorch import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100]\n",
    "}\n",
    "ppl = Pipeline([\n",
    "    ('svm', clf)\n",
    "])\n",
    "search = GridSearchCV(ppl, \n",
    "                      param_grid, \n",
    "                      iid=False, \n",
    "                      cv=StratifiedKFold(n_splits=7),\n",
    "                      return_train_score=False,\n",
    "                      verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderPipeline(NeuralNet):\n",
    "    def get_loss(self, y_pred, y_true, *args, **kwargs):\n",
    "        decoded, _encoded = y_pred\n",
    "        return super().get_loss(decoded, y_true, *args, **kwargs)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        if not self.warm_start or not self.initialized_:\n",
    "            self.initialize()\n",
    "\n",
    "        self.partial_fit(X, X, **fit_params)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        _decoded, encoded = super().forward(X)\n",
    "        return encoded.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoenc = AutoencoderPipeline(\n",
    "    module__input_size=256,\n",
    "    module__encode_dim=(64, 16),\n",
    "    module=Autoencoder,\n",
    "    max_epochs=100,\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__lr=1,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='auto')\n",
    "param_grid = {\n",
    "#     'autofeat__optimizer__lr': [0.1, 1],\n",
    "    'autofeat__module__encode_dim': [(128, 64), (128, 32), (96, 24), (64, 16), (64, 8)],\n",
    "    'svm__C': [10, 100]\n",
    "}\n",
    "\n",
    "best_grid = {\n",
    "    'autofeat__module__encode_dim': [(128, 64), (128, 32), (96, 24), (64, 16)],\n",
    "    'svm__C': [10, 100]\n",
    "}\n",
    "\n",
    "ppl = Pipeline([\n",
    "    ('autofeat', autoenc),\n",
    "    ('svm', clf)\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(ppl, \n",
    "                  best_grid, \n",
    "                  verbose=10,\n",
    "                  cv=StratifiedKFold(n_splits=7),\n",
    "                  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 8 candidates, totalling 56 fits\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.9732313575525813, total=  33.7s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   34.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.9760536398467433, total=  42.2s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.9616858237547893, total=  40.0s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.978866474543708, total=  40.1s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.9817131857555341, total=  42.9s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.971126082771896, total=  44.6s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=10 ...............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  4.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=10, score=0.9749518304431599, total=  46.5s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9770554493307839, total=  47.7s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  5.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9712643678160919, total=  45.5s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  6.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9693486590038314, total=  47.8s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9750240153698367, total=  47.0s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9797882579403272, total=  46.0s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9701636188642926, total=  50.0s\n",
      "[CV] autofeat__module__encode_dim=(128, 64), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 64), svm__C=100, score=0.9739884393063584, total=  44.0s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.9741873804971319, total=  36.4s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.9741379310344828, total=  35.1s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.9664750957854407, total=  34.1s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.9731027857829011, total=  33.8s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.9826756496631376, total=  38.3s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.9701636188642926, total=  34.4s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=10 ...............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=10, score=0.976878612716763, total=  36.3s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.9808795411089866, total=  39.6s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.9712643678160919, total=  40.8s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.9693486590038314, total=  36.7s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.9740634005763689, total=  42.9s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.983638113570741, total=  42.4s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.9720885466794995, total=  42.2s\n",
      "[CV] autofeat__module__encode_dim=(128, 32), svm__C=100 ..............\n",
      "[CV]  autofeat__module__encode_dim=(128, 32), svm__C=100, score=0.976878612716763, total=  34.6s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9760994263862333, total=  37.1s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9760536398467433, total=  36.6s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9655172413793104, total=  40.0s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9740634005763689, total=  37.0s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9797882579403272, total=  33.0s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9692011549566891, total=  43.0s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=10, score=0.9816955684007708, total=  56.8s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.9760994263862333, total= 1.2min\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.9674329501915708, total= 1.2min\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.9626436781609196, total= 1.2min\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.9750240153698367, total= 1.2min\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.9797882579403272, total= 1.3min\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.9778633301251203, total=  58.6s\n",
      "[CV] autofeat__module__encode_dim=(96, 24), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(96, 24), svm__C=100, score=0.976878612716763, total= 1.0min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9674952198852772, total= 1.1min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9655172413793104, total=  54.9s\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9597701149425287, total=  48.7s\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9548511047070125, total= 1.0min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9663137632338787, total=  55.1s\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9615014436958614, total=  43.0s\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=10 ................\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=10, score=0.9710982658959537, total= 1.1min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.9674952198852772, total= 1.1min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.9636015325670498, total= 1.2min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.9501915708812261, total= 1.1min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.9606147934678194, total= 1.0min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.971126082771896, total= 1.1min\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.9653512993262753, total=  50.0s\n",
      "[CV] autofeat__module__encode_dim=(64, 16), svm__C=100 ...............\n",
      "[CV]  autofeat__module__encode_dim=(64, 16), svm__C=100, score=0.9633911368015414, total=  48.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  56 out of  56 | elapsed: 46.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=7, random_state=None, shuffle=False),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('autofeat', <class '__main__.AutoencoderPipeline'>[uninitialized](\n",
       "  module=<class '__main__.Autoencoder'>,\n",
       "  module__encode_dim=(64, 16),\n",
       "  module__input_size=256,\n",
       ")), ('svm', SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'autofeat__module__encode_dim': [(128, 64), (128, 32), (96, 24), (64, 16)], 'svm__C': [10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754491839253875"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:42857\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:46427/status' target='_blank'>http://127.0.0.1:46427/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>16.69 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:42857' processes=4 cores=8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 7 folds for each of 4 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend DaskDistributedBackend with 8 concurrent workers.\n",
      "tornado.application - ERROR - Exception in callback <bound method Nanny.memory_monitor of <Nanny: tcp://127.0.0.1:32875, threads: 2>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_common.py\", line 341, in wrapper\n",
      "    ret = self._cache[fun]\n",
      "AttributeError: 'Process' object has no attribute '_cache'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_pslinux.py\", line 1514, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_pslinux.py\", line 1746, in memory_info\n",
      "    with open_binary(\"%s/%s/statm\" % (self._procfs_path, self.pid)) as f:\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_common.py\", line 586, in open_binary\n",
      "    return open(fname, \"rb\", **kwargs)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/proc/6040/statm'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/tornado/ioloop.py\", line 907, in _run\n",
      "    return self.callback()\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/distributed/nanny.py\", line 274, in memory_monitor\n",
      "    memory = proc.memory_info().rss\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_common.py\", line 344, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/__init__.py\", line 1166, in memory_info\n",
      "    return self._proc.memory_info()\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_pslinux.py\", line 1525, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\n",
      "psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=6040)\n",
      "tornado.application - ERROR - Exception in callback <bound method Nanny.memory_monitor of <Nanny: tcp://127.0.0.1:39075, threads: 2>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_common.py\", line 341, in wrapper\n",
      "    ret = self._cache[fun]\n",
      "AttributeError: 'Process' object has no attribute '_cache'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_pslinux.py\", line 1514, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_pslinux.py\", line 1746, in memory_info\n",
      "    with open_binary(\"%s/%s/statm\" % (self._procfs_path, self.pid)) as f:\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_common.py\", line 586, in open_binary\n",
      "    return open(fname, \"rb\", **kwargs)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/proc/6091/statm'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/tornado/ioloop.py\", line 907, in _run\n",
      "    return self.callback()\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/distributed/nanny.py\", line 274, in memory_monitor\n",
      "    memory = proc.memory_info().rss\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_common.py\", line 344, in wrapper\n",
      "    return fun(self)\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/__init__.py\", line 1166, in memory_info\n",
      "    return self._proc.memory_info()\n",
      "  File \"/home/nemesszili/.conda/envs/gait_torch/lib/python3.6/site-packages/psutil/_pslinux.py\", line 1525, in wrapper\n",
      "    raise NoSuchProcess(self.pid, self._name)\n",
      "psutil.NoSuchProcess: psutil.NoSuchProcess process no longer exists (pid=6091)\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n",
      "distributed.nanny - WARNING - Restarting worker\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-9221835989c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    833\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/sklearn/externals/joblib/_dask.py\u001b[0m in \u001b[0;36mget\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget\u001b[0m  \u001b[0;31m# monkey patch to achieve AsyncResult API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# shorten error traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         result = self.client.sync(self._result, callback_timeout=timeout,\n\u001b[0;32m--> 195\u001b[0;31m                                   raiseit=False)\n\u001b[0m\u001b[1;32m    196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/gait_torch/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "with joblib.parallel_backend('dask'):\n",
    "    gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import GridSearchCV as DaskGridSearchCV\n",
    "\n",
    "dgs = DaskGridSearchCV(ppl, \n",
    "                       best_grid,\n",
    "                       cv=StratifiedKFold(n_splits=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1845</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.4165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.9115</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>0.2630</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0935</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.8810</td>\n",
       "      <td>0.5630</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.4105</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3635</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.7250</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.7680</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.3980</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7330</td>\n",
       "      <td>0.8195</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>0.4005</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2       3       4       5       6       7       8       9    ...  \\\n",
       "0  0.0  0.0  0.0  0.0000  0.0000  0.0000  0.0000  0.1845  0.9310  0.4165  ...   \n",
       "1  0.0  0.0  0.0  0.0935  0.1645  0.0955  0.0565  0.1645  0.0735  0.0000  ...   \n",
       "2  0.0  0.0  0.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0020  ...   \n",
       "3  0.0  0.0  0.0  0.0000  0.0000  0.3635  0.8420  0.9800  0.7250  0.4665  ...   \n",
       "4  0.0  0.0  0.0  0.0000  0.0000  0.0360  0.3980  0.8755  0.7330  0.6170  ...   \n",
       "\n",
       "      246     247     248     249     250     251     252     253    254  255  \n",
       "0  0.6520  0.9115  1.0000  0.7410  0.2630  0.0045  0.0000  0.0000  0.000  0.0  \n",
       "1  0.1645  0.1645  0.4835  0.8805  0.8810  0.5630  0.4525  0.1645  0.086  0.0  \n",
       "2  0.0000  0.0000  0.0000  0.4455  1.0000  0.4105  0.0000  0.0000  0.000  0.0  \n",
       "3  0.3410  1.0000  0.7680  0.0065  0.0000  0.0000  0.0000  0.0000  0.000  0.0  \n",
       "4  0.7330  0.8195  1.0000  1.0000  0.8955  0.7195  0.4005  0.0585  0.000  0.0  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "dd_X_train = dd.from_pandas(pd.DataFrame(data=X_train), npartitions=10)\n",
    "dd_y_train = dd.from_pandas(pd.DataFrame(data=y_train), npartitions=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': [{'autofeat__module__encode_dim': (128, 64), 'svm__C': 10}, {'autofeat__module__encode_dim': (128, 64), 'svm__C': 100}, {'autofeat__module__encode_dim': (128, 32), 'svm__C': 10}, {'autofeat__module__encode_dim': (128, 32), 'svm__C': 100}, {'autofeat__module__encode_dim': (96, 24), 'svm__C': 10}, {'autofeat__module__encode_dim': (96, 24), 'svm__C': 100}, {'autofeat__module__encode_dim': (64, 16), 'svm__C': 10}, {'autofeat__module__encode_dim': (64, 16), 'svm__C': 100}], 'mean_fit_time': array([580.35976265, 579.42765793, 598.21158357, 597.48921524,\n",
      "       525.87829627, 526.53945013, 425.38152682, 425.53063703]), 'std_fit_time': array([17.77972932, 17.3473625 , 17.77235805, 18.1116907 , 26.53854533,\n",
      "       26.93580177, 93.87323286, 94.19586357]), 'mean_score_time': array([3.71498969, 2.73893485, 2.25100453, 2.05092291, 1.89753407,\n",
      "       1.86171152, 0.95281335, 0.80576249]), 'std_score_time': array([0.85422996, 0.51887139, 0.2857832 , 0.511198  , 0.34529336,\n",
      "       0.40659089, 0.56897885, 0.43198641]), 'split0_test_score': array([0.97131931, 0.9751434 , 0.9751434 , 0.97705545, 0.97418738,\n",
      "       0.97801147, 0.95984704, 0.95984704]), 'split1_test_score': array([0.97509579, 0.97701149, 0.97509579, 0.97222222, 0.96934866,\n",
      "       0.9664751 , 0.97030651, 0.9664751 ]), 'split2_test_score': array([0.96455939, 0.96743295, 0.97222222, 0.97126437, 0.96743295,\n",
      "       0.9664751 , 0.94923372, 0.94827586]), 'split3_test_score': array([0.97790586, 0.97598463, 0.97694524, 0.9740634 , 0.97118156,\n",
      "       0.96829971, 0.97118156, 0.96541787]), 'split4_test_score': array([0.98267565, 0.98363811, 0.9759384 , 0.97786333, 0.98267565,\n",
      "       0.98460058, 0.96823869, 0.96631376]), 'split5_test_score': array([0.97208855, 0.97497594, 0.96727623, 0.97497594, 0.96823869,\n",
      "       0.97305101, 0.96246391, 0.95957652]), 'split6_test_score': array([0.977842  , 0.97495183, 0.977842  , 0.97398844, 0.97495183,\n",
      "       0.977842  , 0.97013487, 0.96917148]), 'mean_test_score': array([0.9744891 , 0.97558634, 0.97435194, 0.9744891 , 0.97256892,\n",
      "       0.97352901, 0.96447675, 0.96214511]), 'std_test_score': array([0.00540849, 0.00438289, 0.00331755, 0.00221077, 0.00489381,\n",
      "       0.0064176 , 0.0074015 , 0.00655442]), 'rank_test_score': array([2, 1, 4, 2, 6, 5, 7, 8], dtype=int32), 'split0_train_score': array([0.99391513, 0.99967974, 0.99679744, 0.99967974, 0.9959968 ,\n",
      "       0.99967974, 0.98590873, 0.99839872]), 'split1_train_score': array([0.99359693, 0.99967985, 0.99711862, 0.99983992, 0.99295662,\n",
      "       0.99983992, 0.98975508, 0.99871939]), 'split2_train_score': array([0.99343685, 0.99951977, 0.99727869, 0.99983992, 0.99727869,\n",
      "       0.99967985, 0.9868737 , 0.99887946]), 'split3_train_score': array([0.99488, 0.99968, 0.9976 , 0.99968, 0.99376, 0.99968, 0.98896,\n",
      "       0.9992 ]), 'split4_train_score': array([0.9934421 , 0.9996801 , 0.99744082, 0.9996801 , 0.99152271,\n",
      "       0.9993602 , 0.98560461, 0.99872041]), 'split5_train_score': array([0.99472169, 0.9996801 , 0.99664107, 0.99984005, 0.9934421 ,\n",
      "       0.99984005, 0.99216251, 0.99984005]), 'split6_train_score': array([0.99536223, 0.99968015, 0.99632177, 0.99968015, 0.99360307,\n",
      "       0.99952023, 0.98720614, 0.99888054]), 'mean_train_score': array([0.99419356, 0.9996571 , 0.99702834, 0.99974856, 0.99408   ,\n",
      "       0.99965714, 0.98806725, 0.99894837]), 'std_train_score': array([7.25721231e-04, 5.60661584e-05, 4.25994377e-04, 7.91626973e-05,\n",
      "       1.79061988e-03, 1.58262934e-04, 2.18131105e-03, 4.26661257e-04]), 'param_autofeat__module__encode_dim': masked_array(data=[(128, 64), (128, 64), (128, 32), (128, 32), (96, 24),\n",
      "                   (96, 24), (64, 16), (64, 16)],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_svm__C': masked_array(data=[10, 100, 10, 100, 10, 100, 10, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object)}\n",
      "CPU times: user 7min 36s, sys: 1min 22s, total: 8min 58s\n",
      "Wall time: 36min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dgs.fit(X_train, y_train)\n",
    "print(dgs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755863393224523"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9436970602889886"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgs.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autofeat__module__encode_dim': (128, 64), 'svm__C': 100}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
