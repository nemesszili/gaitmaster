{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/45113245/how-to-get-mini-batches-in-pytorch-in-a-clean-and-efficient-way\n",
    "# https://distill.pub/2016/misread-tsne/\n",
    "# http://setosa.io/ev/principal-component-analysis/\n",
    "# https://stackoverflow.com/questions/50544730/how-do-i-split-a-custom-dataset-into-training-and-test-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION = 1\n",
    "SPLIT = 128\n",
    "RANDOM_SEED = 42\n",
    "SHUFFLE = True\n",
    "\n",
    "VALIDATION_SPLIT = 0.2\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "INPUT_SIZE = 59\n",
    "ENCODE_DIM = 8\n",
    "LOG_EMBED = False\n",
    "\n",
    "BASE_FOLDER = Path('../data')\n",
    "SESSIONS = {0: 22, 1: 153, 2: 153}\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaitDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        df = pd.read_csv(BASE_FOLDER.joinpath(Path(filename)), header=None)\n",
    "        y = df[df.columns[-1]].values\n",
    "        df.drop([df.columns[-1]], axis=1, inplace=True)\n",
    "        y = LabelEncoder().fit_transform(y)\n",
    "        \n",
    "        self.Xdata = df\n",
    "        self.Ydata = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Xdata)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        vector = self.Xdata.iloc[index, :].values.astype(np.float32)\n",
    "        label  = self.Ydata[index]\n",
    "        \n",
    "        return vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(session, split):\n",
    "    return 'zju_gaitaccel_session_' + str(session) + '_' + str(split) + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gait_dataset = GaitDataset(get_csv(SESSION, SPLIT))\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(gait_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(VALIDATION_SPLIT * dataset_size))\n",
    "if SHUFFLE:\n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "\n",
    "train_loader = DataLoader(gait_dataset, batch_size=BATCH_SIZE, \n",
    "                          sampler=train_sampler)\n",
    "valid_loader = DataLoader(gait_dataset, batch_size=BATCH_SIZE,\n",
    "                          sampler=valid_sampler)\n",
    "lossloader = DataLoader(gait_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, ENCODE_DIM),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.decoder = nn.Sequential(             \n",
    "            nn.Linear(ENCODE_DIM, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, INPUT_SIZE))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_enc = self.encoder(x)\n",
    "        x_dec = self.decoder(x_enc)\n",
    "        return x_dec, x_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.tensor([1, 2, 3])\n",
    "x1_rep = x1.view(-1, 1).repeat(1, 4).view(1, 12)\n",
    "x1_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.tensor([1, 2, 3, 4])\n",
    "x2_rep = x2.repeat(1, 3)\n",
    "x2_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24, -1, -1, -1, -1, 24, -1, -1, -1, -1, 24, -1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x1_rep == x2_rep).to(device, dtype=torch.int32) * 25 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparatorLoss(nn.Module):\n",
    "    def __init__(self, loader, encoder):\n",
    "        super(SeparatorLoss, self).__init__()\n",
    "        self.loader = loader\n",
    "        self.loader_iter = iter(loader)\n",
    "        self.encoder = encoder\n",
    "        self.pdist = nn.PairwiseDistance(p=2)\n",
    "        \n",
    "    def forward(self, x_pred, x_true, encoded, labels, n_iter):    \n",
    "        # Get a batch from the same dataset\n",
    "        try:\n",
    "            batch_X, batch_y = next(self.loader_iter)\n",
    "        except StopIteration:\n",
    "            self.loader_iter = iter(self.loader)\n",
    "            batch_X, batch_y = next(self.loader_iter)\n",
    "\n",
    "        # Encode it\n",
    "        batch_encoded = self.encoder(batch_X)\n",
    "        outer_batch_size = batch_y.shape[0]\n",
    "        inner_batch_size = labels.shape[0]\n",
    "#         print('OUTER: {}, INNER: {}'.format(outer_batch_size, inner_batch_size))\n",
    "\n",
    "        # Prepare same class vector\n",
    "        X_labels = labels.view(-1, 1).repeat(1, outer_batch_size).view(1, inner_batch_size * outer_batch_size)\n",
    "        batch_labels = batch_y.repeat(1, inner_batch_size)\n",
    "        same = (X_labels == batch_labels).to(device, dtype=torch.float32)\n",
    "#         print(same.sum())\n",
    "        same = same * (SESSIONS[SESSION] ** 2) - 1\n",
    "\n",
    "        # Prepare matrices\n",
    "        dist_X = encoded.repeat(1, outer_batch_size).view(-1, ENCODE_DIM)\n",
    "        dist_batch = batch_encoded.expand(inner_batch_size, outer_batch_size, ENCODE_DIM).reshape(-1, ENCODE_DIM)\n",
    "\n",
    "        # Calculate pairwise distances\n",
    "        # TODO: divide by BATCH_SIZE?!\n",
    "        sep = (self.pdist(dist_X, dist_batch) * same).sum() / BATCH_SIZE\n",
    "        if self.training:\n",
    "            writer.add_scalar('data/sep', sep, n_iter)\n",
    " \n",
    "        mse = F.mse_loss(x_pred, x_true)\n",
    "        if self.training:\n",
    "            writer.add_scalar('data/mse', mse, n_iter)\n",
    "#         print('sep: {:.4f}, mse: {:.4f}'.format(sep, mse))\n",
    "        return sep + mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, batch_idx, loss_fn):\n",
    "    loss_fn.train()\n",
    "    losses = np.array([])\n",
    "    for data in train_loader:\n",
    "        vec, labels = data\n",
    "        vec = Variable(vec, requires_grad=True).cpu()\n",
    "        \n",
    "        # ===================forward=====================\n",
    "        dec, enc = model(vec)\n",
    "        loss = distance(dec, vec, enc, labels, batch_idx)\n",
    "        losses = np.append(losses, loss.item())\n",
    "        \n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_idx += 1\n",
    "    avg_loss = np.average(losses)\n",
    "    \n",
    "    # ===================validate========================\n",
    "    loss_fn.eval()\n",
    "    val_losses = np.array([])\n",
    "    for data in valid_loader:\n",
    "        vec, labels = data\n",
    "        vec = Variable(vec, requires_grad=False).cpu()\n",
    "        \n",
    "        # ===================forward=====================\n",
    "        dec, enc = model(vec)\n",
    "        val_loss = distance(dec, vec, enc, labels, 0).item()\n",
    "        val_losses = np.append(val_losses, val_loss)\n",
    "    \n",
    "    avg_val_loss = np.average(val_losses)\n",
    "    \n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], train_loss: {:.4f}, val_loss: {:.4f}'.format(epoch + 1, EPOCHS, avg_loss, avg_val_loss))\n",
    "    writer.add_scalars('data/loss', {'train_loss': avg_loss,\n",
    "                                     'val_loss': avg_val_loss}, \n",
    "                                     epoch + 1)\n",
    "    \n",
    "    # Add embeddings\n",
    "    if LOG_EMBED:\n",
    "        if epoch % 10 == 0:\n",
    "            encs = torch.Tensor([])\n",
    "            labels = []\n",
    "            for data in train_loader:\n",
    "                vec, label = data\n",
    "                vec = Variable(vec).cpu()\n",
    "                _, enc = model(vec)\n",
    "\n",
    "                encs = torch.cat((encs, enc))\n",
    "                labels.extend([str(l.tolist()) for l in label])\n",
    "            \n",
    "        writer.add_embedding(encs, metadata=labels, global_step=epoch + 1, tag='train')\n",
    "        \n",
    "    # writer.export_scalars_to_json('./all_scalars.json')\n",
    "    return batch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/10], train_loss: 21.0586, val_loss: 0.2064\n",
      "epoch [2/10], train_loss: 0.2100, val_loss: 0.2021\n",
      "epoch [3/10], train_loss: 0.2050, val_loss: 0.1996\n",
      "epoch [4/10], train_loss: 0.2044, val_loss: 0.2007\n",
      "epoch [5/10], train_loss: 0.2018, val_loss: 0.1972\n",
      "epoch [6/10], train_loss: 0.1989, val_loss: 0.1941\n",
      "epoch [7/10], train_loss: 0.1974, val_loss: 0.1911\n",
      "epoch [8/10], train_loss: 0.1956, val_loss: 0.1888\n",
      "epoch [9/10], train_loss: 0.1927, val_loss: 0.1875\n",
      "epoch [10/10], train_loss: 0.1905, val_loss: 0.1838\n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter(log_dir='runs/SeparatorTestEmbed')\n",
    "writer = SummaryWriter()\n",
    "model = Autoencoder().cpu()\n",
    "distance = SeparatorLoss(lossloader, model.encoder)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.0003, momentum = 0.9)\n",
    "\n",
    "train_idx = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    train_idx = train(epoch, train_idx, distance)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
